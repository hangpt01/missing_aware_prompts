config:
  batch_size: 32
  both_ratio: 0.5
  data_root: datasets/Food101
  datasets: Food101
  decay_power: 1
  draw_false_image: 0
  draw_false_text: 0
  drop_rate: 0.1
  end_lr: 0
  exp_name: food101
  fast_dev_run: false
  finetune_first: false
  fix_model: true
  food101_class_num: 101
  get_recall_metric: false
  hatememes_class_num: 2
  hidden_size: 768
  image_only: false
  image_size: 384
  learning_rate: 0.01
  learnt_p: true
  load_path: vilt/pretrained_model_weight/vilt_200k_mlm_itm.ckpt
  log_dir: result
  loss_names:
    food101: 1
    hatememes: 0
    irtr: 0
    itm: 0
    mlm: 0
    mmimdb: 0
    mpp: 0
    mppd: 0
    nlvr2: 0
    vqa: 0
  lr_mult: 1
  max_epoch: 20
  max_image_len: -1
  max_steps: null
  max_text_len: 40
  missing_ratio:
    test: 0.7
    train: 0.7
    val: 0.7
  missing_table_root: ./datasets/missing_tables/
  missing_type:
    test: both
    train: both
    val: both
  mlm_prob: 0.15
  mlp_ratio: 4
  mmimdb_class_num: 23
  multi_layer_prompt: true
  num_gpus: 1
  num_heads: 12
  num_layers: 12
  num_nodes: 1
  num_workers: 8
  optim_type: adamw
  patch_size: 32
  per_gpu_batchsize: 4
  precision: 16
  prompt_layers:
  - 0
  - 1
  - 2
  - 3
  - 4
  - 5
  prompt_length: 16
  prompt_type: input
  resume_from: null
  seed: 0
  simulate_missing: false
  test_exp_name: null
  test_only: false
  test_ratio: null
  test_type: null
  tokenizer: bert-base-uncased
  train_transform_keys:
  - pixelbert
  val_check_interval: 0.2
  val_transform_keys:
  - pixelbert
  vit: vit_base_patch32_384
  vocab_size: 30522
  vqav2_label_size: 3129
  warmup_steps: 0.1
  weight_decay: 0.02
  whole_word_masking: false
